{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346df0aa-4d8e-4a0a-8648-5ab167877b6a",
   "metadata": {},
   "source": [
    "# RGB to XYZ \n",
    "Transformation from RGB to XYZ is a simple matrix multiplication<br>\n",
    "$[X Y Z] = M \\times [R G B]$<br>\n",
    "The Matrix M is a standard matrix based on the standard whitepoint of monitors. HOWEVER, when we measure the _specific_ whitepoint of our monitor, we can refine the conversion.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "583744d1-6466-4eae-85a7-6e9afc1abba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# use the os\n",
    "import os\n",
    "import glob\n",
    "# math and data structure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# image processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63423b28-0831-4cb6-86d6-8bec54fb8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_dir = os.path.join('..','stimuli')\n",
    "# taken from original - added alpha channel\n",
    "true_color_stim_dir = os.path.join(stim_dir,'true_color')\n",
    "if not os.path.exists(true_color_stim_dir):\n",
    "    os.mkdir(true_color_stim_dir)\n",
    "inverted_lab_stim_dir = os.path.join(stim_dir,'inverted_lab')\n",
    "if not os.path.exists(inverted_lab_stim_dir):\n",
    "    os.mkdir(inverted_lab_stim_dir)\n",
    "inverted_lab_stim_dir_refined = os.path.join(stim_dir,'inverted_lab_refined')\n",
    "if not os.path.exists(inverted_lab_stim_dir_refined):\n",
    "    os.mkdir(inverted_lab_stim_dir_refined)\n",
    "    \n",
    "foreground_background_mask_dir = os.path.join(stim_dir,'foreground_background_masks')\n",
    "if not os.path.exists(foreground_background_mask_dir):\n",
    "    os.mkdir(foreground_background_mask_dir)\n",
    "color_mask_dir = os.path.join(stim_dir, 'color_masks')\n",
    "if not os.path.exists(color_mask_dir):\n",
    "    os.mkdir(color_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "288d0316-5c19-4323-a9ad-86eb62a310be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M taken from Measurement at CIN 2nd floor\n",
    "def rgb2xyz(img):\n",
    "    # sanity checks that the provided image is actually a X*Y*3 image\n",
    "    if type(img) is not np.ndarray:\n",
    "        print('Input image was not a numpy array')\n",
    "        return False\n",
    "    if len(img.shape)!=3:\n",
    "        print('Array is not three dimensional')\n",
    "        return False\n",
    "    if img.shape[2]!=3:\n",
    "        print('The images color channel does not have three (R-G-B) dimensions')\n",
    "        return False\n",
    "    # sanity check that image is one of the opencv supported file types\n",
    "    if img.dtype=='float32':\n",
    "        cap = 1\n",
    "    elif img.dtype=='uint8':\n",
    "        cap = 255\n",
    "    elif img.dtype=='float64':\n",
    "        cap=1\n",
    "    else:\n",
    "        print('Unsupported data type')\n",
    "        raise AssertionError()\n",
    "    \n",
    "    # RGB to XYZ transformation matrix derived from monitor calibration\n",
    "    M = np.array([[0.4040,0.3602,0.1987],\n",
    "                  [0.2041,0.7307,0.0652],\n",
    "                  [0.0050,0.0731,1.0797]])\n",
    "    \n",
    "    # tensordot does the matrix multiplication along the right dimension\n",
    "    xyz_img = np.tensordot(img,M.T, axes=1)\n",
    "    # xyz_img = np.clip(xyz_img,0,cap)\n",
    "    xyz_img = xyz_img.astype(img.dtype)\n",
    "    return(xyz_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a0326f-7cb9-42e3-ac43-7db5282cf230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function f and the xyz to lab transformation are taken from here:\n",
    "# https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html\n",
    "def f(t):\n",
    "    output = t.copy()\n",
    "    output[t>0.008856] = t[t>0.008856]**(1/3)\n",
    "    output[t<=0.008856] = t[t<=0.008856]*7.787+(16/116)\n",
    "    return output\n",
    "def xyz2lab(xyz):\n",
    "    if xyz.dtype=='float32':\n",
    "        delta = 0\n",
    "    elif xyz.dtype=='uint8':\n",
    "        delta = 128\n",
    "        xyz = xyz.astype(np.float32)/255\n",
    "    else:\n",
    "        print('Unsupported data type')\n",
    "        print(xyz.dtype)\n",
    "        delta = 0\n",
    "        \n",
    "    # X_n, Y_n, Z_n taken from measurement at CIN 2nd floor\n",
    "    X_n = 149.0/100\n",
    "    Y_n = 154.8/100\n",
    "    Z_n = 179.3/100\n",
    "    \n",
    "    X,Y,Z = cv2.split(xyz)\n",
    "    X = X/X_n\n",
    "    Y = Y/Y_n\n",
    "    Z = Z/Z_n\n",
    "    L = np.zeros_like(Y)\n",
    "    a = np.zeros_like(X)\n",
    "    b = np.zeros_like(Z)\n",
    "    \n",
    "    L[Y>0.008856] = Y[Y>0.008856]**(1/3)*116-16\n",
    "    L[Y<=0.008856] = 903.3*Y[Y<=0.008856]\n",
    "    \n",
    "    a = 500*(f(X) - f(Y)) + delta\n",
    "    b = 200*(f(Y) - f(Z)) + delta\n",
    "    \n",
    "    lab = cv2.merge((L,a,b))\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89edbfc-364b-4cc6-bc94-166333835796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2lab(rgb):\n",
    "    xyz = rgb2xyz(rgb)\n",
    "    lab = xyz2lab(xyz)\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6341d574-87c1-4f6c-bf16-0ed954873185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backtransformation was taken frome here:\n",
    "# https://github.com/scikit-image/scikit-image/blob/main/skimage/color/colorconv.py\n",
    "def lab2xyz(lab):\n",
    "    L,a,b = cv2.split(lab)\n",
    "    \n",
    "    Y = L.copy()\n",
    "    X = a.copy()\n",
    "    Z = b.copy()\n",
    "    \n",
    "    Y = (L+16.0) / 116.0\n",
    "    X = (a / 500) + Y\n",
    "    Z = Y - (b / 200.0)\n",
    "    \n",
    "    Z[Z < 0] = 0\n",
    "    \n",
    "    xyz = cv2.merge((X,Y,Z))\n",
    "    mask = xyz > 0.2068966\n",
    "    xyz[mask] = xyz[mask]**3.0\n",
    "    xyz[~mask] = (xyz[~mask] - 16.0 / 116.) / 7.787\n",
    "    \n",
    "    xyz[:,:,0] *= 149.0/100\n",
    "    xyz[:,:,1] *= 154.8/100\n",
    "    xyz[:,:,2] *= 179.3/100\n",
    "    \n",
    "    return xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c6b136a-8ab8-4531-be14-0d4f0cdc6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz2rgb(xyz):\n",
    "    if xyz.dtype == np.float32:\n",
    "        cap = 1.0\n",
    "    elif xyz.dtype == np.uint8:\n",
    "        cap = 255\n",
    "    else:\n",
    "        print('Unsupported data type')\n",
    "        raise AssertionError()\n",
    "        \n",
    "    M = np.array([[0.4040,0.3602,0.1987],\n",
    "                  [0.2041,0.7307,0.0652],\n",
    "                  [0.0050,0.0731,1.0797]])\n",
    "    \n",
    "    M_inv = np.linalg.inv(M)\n",
    "    \n",
    "    rgb = np.tensordot(xyz,M_inv.T, axes=1)\n",
    "    rgb = np.clip(rgb,0,cap)\n",
    "    rgb = rgb.astype(xyz.dtype)\n",
    "    return(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be735b1-f2b4-49cf-90b2-128f9be083b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab2rgb(lab):\n",
    "    xyz = lab2xyz(lab)\n",
    "    rgb = xyz2rgb(xyz)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701bc88b-dad6-41d5-ac2d-fa75415a2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all stimuli in the directory\n",
    "stimuli_full_path = glob.glob(os.path.join(true_color_stim_dir,'*.png'))\n",
    "stimuli_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "stimuli = [os.path.basename(stim) for stim in stimuli_full_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd6f4428-8d71-4168-81e0-ea2715868596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stim in stimuli:\n",
    "    # get true color stimlus directory\n",
    "    true_stim_dir = os.path.join(true_color_stim_dir,stim)\n",
    "    # get inverted color stimulus directory\n",
    "    inv_stim_dir = os.path.join(inverted_lab_stim_dir,stim)\n",
    "    # get stimulus mask\n",
    "    mask_dir = os.path.join(foreground_background_mask_dir,stim)\n",
    "    \n",
    "    # read in the image\n",
    "    true_img = cv2.imread(true_stim_dir)\n",
    "    # convert image from BGR to RGB\n",
    "    true_rgb = cv2.cvtColor(true_img, cv2.COLOR_BGR2RGB)\n",
    "    # convert image from unsigned integer to float and change range to 0-1\n",
    "    true_rgb = true_rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "    # read in the mask\n",
    "    mask_img = cv2.imread(mask_dir)\n",
    "    # the mask has three channels and values are 0 or 255 -> make it a 2D boolean mask\n",
    "    mask = mask_img[:,:,0].astype(bool)\n",
    "    \n",
    "    # convert image from RGB to LAB\n",
    "    true_lab = rgb2lab(true_rgb)\n",
    "    \n",
    "    # invert the image\n",
    "    L,a,b = cv2.split(true_lab)\n",
    "    a_inv = -a\n",
    "    b_inv = -b\n",
    "    \n",
    "    inv_lab = cv2.merge((L,a_inv,b_inv))\n",
    "    \n",
    "    # convert image from inverted lab back to rgb\n",
    "    inv_rgb = lab2rgb(inv_lab)\n",
    "    # convert image back into unsigned int\n",
    "    inv_rgb = (inv_rgb*255.0).astype(np.uint8)\n",
    "    \n",
    "    # change to BGR and add alpha channel to image \n",
    "    inv_rgba = cv2.cvtColor(inv_rgb, cv2.COLOR_RGB2BGRA)\n",
    "    \n",
    "    # make background invisible\n",
    "    inv_rgba[~mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    \n",
    "    # save image\n",
    "    cv2.imwrite(inv_stim_dir, inv_rgba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5bcc8-a00e-4652-9c07-b9e8018d6a33",
   "metadata": {},
   "source": [
    "### Refined inverted images\n",
    "In the previous steps we inverted the color of the whole object\n",
    "Now we create inverted images with the refined masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796711a-4ec7-4b51-86df-1c41535aca54",
   "metadata": {},
   "source": [
    "# TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10e696-7aad-4e18-bb24-b286c34e9e24",
   "metadata": {},
   "source": [
    "# Representative colors of stimuli\n",
    "For each stimulus get a representative pixel of the true color and invered color stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bef166f-734e-4798-8074-a3d6cfe88e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store results in\n",
    "rep_pixel_dict = {\n",
    "    'stimuli': [],\n",
    "    'true_R': [],\n",
    "    'true_G': [],\n",
    "    'true_B': [],\n",
    "    'inv_R': [],\n",
    "    'inv_G': [],\n",
    "    'inv_B': [],\n",
    "}\n",
    "\n",
    "stimulus_selection = [\n",
    "    'blue_nivea.png',\n",
    "    'blue_pool.png',\n",
    "    'blue_sign.png',\n",
    "    'green_brokkoli_1.png',\n",
    "    'green_frog_1.png',\n",
    "    'green_lettuce_1.png',\n",
    "    'orange_basketball.png',\n",
    "    'orange_carrots.png',\n",
    "    'orange_pumpkin.png',\n",
    "    'red_fire_extinguisher_1.png',\n",
    "    'red_strawberry.png',\n",
    "    'red_tomato.png',\n",
    "    'yellow_banana.png',\n",
    "    'yellow_chicken.png',\n",
    "    'yellow_corn.png'\n",
    "]\n",
    "\n",
    "for stim in stimulus_selection:\n",
    "    rep_pixel_dict['stimuli'].append(stim)\n",
    "    # get paths of stimuli\n",
    "    true_path = os.path.join(true_color_stim_dir,stim)\n",
    "    inv_path = os.path.join(inverted_lab_stim_dir,stim)\n",
    "    # read in the original and inverted stimuli\n",
    "    true_color_img = cv2.imread(true_path)\n",
    "    inv_color_img = cv2.imread(inv_path)\n",
    "    # convert the image from BRG (opencv default) to RGB (everybodies default)\n",
    "    true_color_img = cv2.cvtColor(true_color_img, cv2.COLOR_BGR2RGB)\n",
    "    inv_color_img = cv2.cvtColor(inv_color_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # read in the mask of the stimulus\n",
    "    mask_path = os.path.join(color_mask_dir, stim)\n",
    "    mask_img = cv2.imread(mask_path)\n",
    "    # the mask is saved as an image with three channels with either 0 or 255 values -> convert to boolean mask\n",
    "    mask_img = mask_img[:,:,0].astype(bool)\n",
    "    \n",
    "    # extract the pixels within the mask\n",
    "    true_pixels = true_color_img[mask_img==1]\n",
    "    inv_pixels = inv_color_img[mask_img==1]\n",
    "    \n",
    "    # get the representative pixel by searching for the pixel values appearing most often\n",
    "    # true pixel\n",
    "    # unique_colors, counts = np.unique(true_pixels,axis=0,return_counts=True)\n",
    "    # most_frequent_indices = np.flip(np.argsort(counts))\n",
    "    # # we need to convert the pixel from np.uint8 to int. Otherwise the transversion to the dataframe messes things up\n",
    "    # most_frequent_true_color = unique_colors[most_frequent_indices[0]].astype(int)\n",
    "    most_frequent_true_color = true_pixels.mean(axis=0)\n",
    "    rep_pixel_dict['true_R'].append(most_frequent_true_color[0])\n",
    "    rep_pixel_dict['true_G'].append(most_frequent_true_color[1])\n",
    "    rep_pixel_dict['true_B'].append(most_frequent_true_color[2])\n",
    "    \n",
    "    # inverted pixel\n",
    "    # unique_colors, counts = np.unique(inv_pixels,axis=0,return_counts=True)\n",
    "    # most_frequent_indices = np.flip(np.argsort(counts))\n",
    "    # # we need to convert the pixel from np.uint8 to int. Otherwise the transversion to the dataframe messes things up\n",
    "    # most_frequent_inverted_color = unique_colors[most_frequent_indices[0]].astype(int)\n",
    "    most_frequent_inverted_color = inv_pixels.mean(axis=0)\n",
    "    rep_pixel_dict['inv_R'].append(most_frequent_inverted_color[0])\n",
    "    rep_pixel_dict['inv_G'].append(most_frequent_inverted_color[1])\n",
    "    rep_pixel_dict['inv_B'].append(most_frequent_inverted_color[2])\n",
    "    \n",
    "# convert the dictionary to a dataframe\n",
    "pixel_df = pd.DataFrame(data=rep_pixel_dict, columns=rep_pixel_dict.keys())\n",
    "pixel_df.to_csv(os.path.join(stim_dir,'representative_pixels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad229693-e948-4d1c-90e1-bf14c0051f39",
   "metadata": {},
   "source": [
    "### Luminance sanity check\n",
    "Changing the color in LAB space resulted in pixels not representable in RGB space.<br>\n",
    "In turn the conversion back results in different colors with different luminances<br>\n",
    "<br>\n",
    "Check the actual differences of luminance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7540f169-fe51-4666-8eae-9c75b670e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lum_diff_dir = os.path.join(results_dir, 'lum_diff')\n",
    "if not os.path.exists(lum_diff_dir):\n",
    "    os.mkdir(lum_diff_dir)\n",
    "    \n",
    "lum_diff_sum = []\n",
    "lum_diff_percent = []\n",
    "\n",
    "for stim in stimuli:\n",
    "    true_path = os.path.join(true_color_stim_dir, stim)\n",
    "    inv_path = os.path.join(inverted_lab_stim_dir, stim)\n",
    "    mask_path = os.path.join(mask_dir, stim)\n",
    "    mask_img = cv2.imread(mask_path)\n",
    "    mask_img = mask_img[:,:,0].astype(bool)\n",
    "\n",
    "    true_color_img = cv2.imread(true_path)\n",
    "    true_lab = cv2.cvtColor(true_color_img, cv2.COLOR_BGR2LAB)\n",
    "    true_L, a, b = cv2.split(true_lab)\n",
    "    \n",
    "    inv_color_img = cv2.imread(inv_path)\n",
    "    inv_lab = cv2.cvtColor(inv_color_img, cv2.COLOR_BGR2LAB)\n",
    "    inv_L, a, b = cv2.split(inv_lab)\n",
    "\n",
    "    true_L_f = true_L.astype(np.float32)\n",
    "    inv_L_f = inv_L.astype(np.float32)\n",
    "    \n",
    "    lum_diff = (true_L_f-inv_L_f)[mask_img==1]\n",
    "    lum_diff_sum.append(lum_diff.sum())\n",
    "    lum_diff_percent.append(sum(lum_diff!=0)/len(lum_diff))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.hist(lum_diff, bins=40)\n",
    "    plt.savefig(os.path.join(lum_diff_dir,stim))\n",
    "    plt.close(fig=fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
