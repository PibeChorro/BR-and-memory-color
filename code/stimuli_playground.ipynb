{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10b476b-2545-49f6-a022-01e596a0cb38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stimulus playground\n",
    "This script is a playground to inspect and manipulate stimuli for a binocular rivalry (BR) experiment<br>\n",
    "In this experiment (as at May 29th) I aim to present objects that are associated with a color (e.g., banana - yellow, strawberry - red) in rivarous situations.<br>\n",
    "1. Show the same stimulus either in the \"correct\" and in an \"incorrect\" color (a banana in yellow and blue)\n",
    "2. Show two different stimuli that are associated with different colors but in the same color (a banana and a strawberry both in yellow)\n",
    "\n",
    "Compare the onset and sustained dominance with rivaling gratings that follow a series of non-rivaling gratings that appear to be rotating (Denison et al., 2011, Attarha et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc02fc-718e-4157-8d1f-061c8c9abb16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stimuli\n",
    "In the following I will look at the stimuli used by Teichmann et al., 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f4fc70-b12f-4ea2-a00a-2a39b416d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# use the os\n",
    "import os\n",
    "import glob\n",
    "# math and data structure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# image processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17581e11-225f-4d53-a5b5-cc8468dea3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimuli from Teichmann et al., 2020\n",
    "# provided by her OSF site (https://osf.io/tcqjh/)\n",
    "stim_dir = os.path.join('..','stimuli')\n",
    "teichmann_stim_dir = os.path.join(stim_dir,'teichmann_2020_stimuli')\n",
    "blue_stim_dir = os.path.join(stim_dir,'blue_stimuli')\n",
    "\n",
    "# taken from original - added alpha channel\n",
    "true_color_stim_dir = os.path.join(stim_dir,'true_color')\n",
    "if not os.path.exists(true_color_stim_dir):\n",
    "    os.mkdir(true_color_stim_dir)\n",
    "# stimuli in LAB space inverted\n",
    "inverted_lab_stim_dir = os.path.join(stim_dir,'inverted_lab')\n",
    "if not os.path.exists(inverted_lab_stim_dir):\n",
    "    os.mkdir(inverted_lab_stim_dir)\n",
    "\n",
    "# masks\n",
    "mask_dir = os.path.join(stim_dir,'masks')\n",
    "if not os.path.exists(mask_dir):\n",
    "    os.mkdir(mask_dir)\n",
    "foreground_background_mask_dir = os.path.join(stim_dir,'foreground_background_masks')\n",
    "if not os.path.exists(foreground_background_mask_dir):\n",
    "    os.mkdir(foreground_background_mask_dir)\n",
    "    \n",
    "# where results of image analyses are saved\n",
    "results_dir = os.path.join(stim_dir,'analysis')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "ab_dist_plot_dir = os.path.join(results_dir, 'ab_distance')\n",
    "if not os.path.exists(ab_dist_plot_dir):\n",
    "    os.mkdir(ab_dist_plot_dir)\n",
    "hue_dist_plot_dir = os.path.join(results_dir, 'hue_distributions')\n",
    "if not os.path.exists(hue_dist_plot_dir):\n",
    "    os.mkdir(hue_dist_plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004866c-20e4-48c5-9c7c-538d1eb23921",
   "metadata": {},
   "source": [
    "### Note\n",
    "Some of the stimuli taken from Teichmann were prepared with the following cell, but created \"wholes\" in the stimuli, because these had pure white pixels in the foreground.<br>\n",
    "The \"wholes\" within the images were filled using GIMP and replaced the originals.<br>\n",
    "The true originals that were replaced are now located in `original_exchanged`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2543699-0e6c-4ae5-bfa7-af2626fdb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_foreground_background_masks(stim_path,output_path):\n",
    "    # read in the original image\n",
    "    img = cv2.imread(stim_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a binary mask for the largest contour\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "    \n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = hls_img[:,:,1]!=255\n",
    "    big_mask = big_mask = np.logical_and(white_mask, binary_mask)\n",
    "    big_mask_img = big_mask.astype(np.uint8)*255\n",
    "    big_mask_img = cv2.cvtColor(big_mask_img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    cv2.imwrite(output_path,big_mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a93ad4-7761-4a5b-81c1-ea151a44b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all stimuli in the directory\n",
    "teichmann_full_path = glob.glob(os.path.join(teichmann_stim_dir,'*.png'))\n",
    "teichmann_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "teichmann_stimuli = [os.path.basename(stim) for stim in teichmann_full_path]\n",
    "\n",
    "for stim in teichmann_stimuli:\n",
    "    stim_path = os.path.join(teichmann_stim_dir, stim)\n",
    "    mask_output_dir = os.path.join(foreground_background_mask_dir, stim)\n",
    "    \n",
    "    create_foreground_background_masks(stim_path=stim_path,output_path=mask_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd95fd2-c781-464b-975a-138fa44f4379",
   "metadata": {},
   "source": [
    "# BLUE\n",
    "Green, red, orange and yellow stimuli were taken from Teichmann 2020 and share many properties<br>\n",
    "The blue stimuli however were taken from google searches and cannot be automatically separated into foreground an background as the other stimuli can<br>\n",
    "Inspect each of the blue stimuli by it self and try to find good parameters to separate them using `opencv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb4a11e-5227-4d92-90f2-546dbe69d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blue_background_foreground_masks(R_channel,G_channel,B_channel, R_thresh, G_thresh, B_thresh):\n",
    "    _, thres_R = cv2.threshold(R, R_thresh[0], R_thresh[1], cv2.THRESH_BINARY_INV)\n",
    "    _, thres_G = cv2.threshold(G, G_thresh[0], G_thresh[1], cv2.THRESH_BINARY_INV)\n",
    "    _, thres_B = cv2.threshold(B, R_thresh[0], R_thresh[1], cv2.THRESH_BINARY_INV)\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    rgb_thres = cv2.merge((thres_R,thres_G,thres_B))\n",
    "    gray_thres = cv2.cvtColor(rgb_thres, cv2.COLOR_RGB2GRAY)\n",
    "    # # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(gray_thres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    mask = np.zeros(gray_thres.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "    \n",
    "    binary_mask_img = binary_mask.astype(np.uint8)\n",
    "    binary_mask_img = cv2.cvtColor(binary_mask_img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e48213-ee95-4f3d-b404-232c34e7fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71 112  76]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NIVEA\n",
    "stim = 'blue_nivea.png'\n",
    "path = os.path.join(blue_stim_dir,stim)\n",
    "img = cv2.imread(path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# RGB values of background are 71,112,76 - even though in the original png they are transparent\n",
    "print(img_rgb[0,0])\n",
    "r_threshold = [70,72]\n",
    "g_threshold = [111,113]\n",
    "b_threshold = [75,77]\n",
    "# create mask using these values to extract the background\n",
    "R, G, B = cv2.split(img_rgb)\n",
    "nivea_mask = create_blue_background_foreground_masks(R_channel=R, G_channel=G,B_channel=B,\n",
    "                                                     R_thresh=r_threshold,G_thresh=g_threshold,B_thresh=b_threshold)\n",
    "# make the mask an image with three channels either white or black\n",
    "cv2.imwrite(os.path.join(foreground_background_mask_dir,stim), nivea_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3934c29-47a5-408a-b218-848e8b9586fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n",
      "[238 239 239]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POOL\n",
    "stim = 'blue_pool.png'\n",
    "path = os.path.join(blue_stim_dir,stim)\n",
    "img = cv2.imread(path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# RGB values of background are 255,255,255 for white background squares\n",
    "print(img_rgb[0,0])\n",
    "# RGB values of background are 238,239,239 for gray background squares\n",
    "print(img_rgb[50,0])\n",
    "gray_pool = cv2.cvtColor(img_rgb,cv2.COLOR_RGB2GRAY)\n",
    "R, G, B = cv2.split(img_rgb)\n",
    "r_threshold = [237,255]\n",
    "g_threshold = [238,255]\n",
    "b_threshold = [238,255]\n",
    "pool_mask = create_blue_background_foreground_masks(R_channel=R, G_channel=G,B_channel=B,\n",
    "                                                    R_thresh=r_threshold,G_thresh=g_threshold,B_thresh=b_threshold)\n",
    "cv2.imwrite(os.path.join(foreground_background_mask_dir,stim), pool_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03e1372-2c55-4354-b763-daa0315f82ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIGN\n",
    "stim = 'blue_sign.png'\n",
    "path = os.path.join(blue_stim_dir,stim)\n",
    "img = cv2.imread(path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# RGB values of background are 0,0,0 \n",
    "print(img_rgb[0,0])\n",
    "# RGB values of the circle and figures in the sign are white\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "black_mask = gray_img != 0\n",
    "# make the mask an image with three channels either white or black\n",
    "sign_mask_img = black_mask.astype(np.uint8)*255\n",
    "sign_mask_img = cv2.cvtColor(sign_mask_img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite(os.path.join(foreground_background_mask_dir,stim), sign_mask_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6958c56-b72c-457e-93a5-7abd07efb3fa",
   "metadata": {},
   "source": [
    "### Distribution of HUE in foreground\n",
    "We want to extract the Hue distribution within the images in order to create refined masks that only cover the parts of the object in the diagnostic color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad4eb5-fc03-4e34-af47-1144f0bbc6e0",
   "metadata": {},
   "source": [
    "## Background transparent\n",
    "Make the background of the stimuli transparent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f6fc7c-75b2-448b-b586-9a46e0a71d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all stimuli in the directory\n",
    "stimuli_full_path = glob.glob(os.path.join(teichmann_stim_dir,'*.png'))\n",
    "stimuli_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "teichmann_stimuli = [os.path.basename(stim) for stim in stimuli_full_path]\n",
    "\n",
    "# read out the original stimuli and remove the background\n",
    "for stim in teichmann_stimuli:\n",
    "    # output directories\n",
    "    teichmann_input_dir = os.path.join(teichmann_stim_dir, stim)\n",
    "    true_color_output_dir = os.path.join(true_color_stim_dir,stim)\n",
    "    current_mask_dir = os.path.join(foreground_background_mask_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(teichmann_input_dir)\n",
    "    mask = cv2.imread(current_mask_dir)\n",
    "    mask = mask[:,:,0].astype(bool)\n",
    "    \n",
    "    bgra_img = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA)\n",
    "    bgra_img[~mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    \n",
    "    cv2.imwrite(true_color_output_dir, bgra_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398740b-db36-4e09-b9f9-649bc9da9973",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Blue stimuli\n",
    "Perform the same on the blue stimuli that are not derived from Teichmann et al., 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188a7236-c53d-4362-ba21-385a75c16e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_stimuli = [\n",
    "    'blue_nivea.png',\n",
    "    'blue_pool.png',\n",
    "    'blue_sign.png'\n",
    "]\n",
    "blue_stim_dir = os.path.join(stim_dir, 'blue_stimuli')\n",
    "# read out the original stimuli and remove the background\n",
    "for stim in blue_stimuli:\n",
    "    # output directories\n",
    "    blue_input_dir = os.path.join(blue_stim_dir, stim)\n",
    "    true_color_output_dir = os.path.join(true_color_stim_dir,stim)\n",
    "    current_mask_dir = os.path.join(foreground_background_mask_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(blue_input_dir)\n",
    "    mask = cv2.imread(current_mask_dir)\n",
    "    mask = mask[:,:,0].astype(bool)\n",
    "    \n",
    "    bgra_img = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA)\n",
    "    bgra_img[~mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    \n",
    "    cv2.imwrite(true_color_output_dir, bgra_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bdb4ff-35c5-4f53-8017-379d52f555e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all stimuli in the directory\n",
    "stimuli_full_path = glob.glob(os.path.join(true_color_stim_dir,'*.png'))\n",
    "stimuli_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "stimuli = [os.path.basename(stim) for stim in stimuli_full_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bdb4ff-35c5-4f53-8017-379d52f555e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stim in stimuli:\n",
    "    # output directories\n",
    "    true_color_input_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    current_mask_dir = os.path.join(foreground_background_mask_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(true_color_input_dir)\n",
    "    mask = cv2.imread(current_mask_dir)\n",
    "    mask = mask[:,:,0].astype(bool)\n",
    "    \n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    H,L,S = cv2.split(hls_img)\n",
    "    # create a histogram of the hue values in the image for later mask creation\n",
    "    fig = plt.figure()\n",
    "    plt.hist(H[mask],bins=50)\n",
    "    plt.savefig(os.path.join(hue_dist_plot_dir,stim))\n",
    "    plt.close(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5a728-2bd2-49f8-b43b-a7485dd42c87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Invert the color in the stimuli\n",
    "This is not performed in the same step because some minor adjustments were made in the true color stimuli using GIMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958d1186-2935-422a-b6d2-6c92451d2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_img(input_dir, mask_dir, refined_mask_dir=None):\n",
    "    # read in the original image\n",
    "    img = cv2.imread(input_dir)\n",
    "    mask = cv2.imread(mask_dir)\n",
    "    mask = mask[:,:,0].astype(bool)\n",
    "    \n",
    "    if refined_mask_dir is None:\n",
    "        refined_mask_dir = mask_dir\n",
    "    \n",
    "    refined_mask = cv2.imread(refined_mask_dir)\n",
    "    refined_mask = refined_mask[:,:,0].astype(bool)\n",
    "    \n",
    "    # convert into LAB and LUV space for inversion\n",
    "    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split the L*a*b* image into its channels\n",
    "    L, a, b = cv2.split(lab_img)\n",
    "    a_inv = a.copy()\n",
    "    b_inv = b.copy()\n",
    "    # Invert the a and b channels\n",
    "    a_inv[refined_mask] = 255 - a[refined_mask]\n",
    "    b_inv[refined_mask] = 255 - b[refined_mask]\n",
    "    \n",
    "    # Merge the inverted channels back into the L*a*b* image\n",
    "    inverted_lab_img = cv2.merge((L, a_inv, b_inv))\n",
    "    inverted_lab_bgr_img = cv2.cvtColor(inverted_lab_img, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # add alpha channel to inverted image by converting from BGR to BGRA space\n",
    "    inverted_lab_bgra_img = cv2.cvtColor(inverted_lab_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # make background (everything outside the mask) transparent (and white)\n",
    "    inverted_lab_bgra_img[~mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    \n",
    "    return inverted_lab_bgra_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a9f9bbb-e37d-4fc8-b631-d574616bea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stim in stimuli:\n",
    "    # output directories\n",
    "    true_color_input_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    current_mask_dir = os.path.join(foreground_background_mask_dir, stim)\n",
    "    inverted_lab_output_dir = os.path.join(inverted_lab_stim_dir, stim)\n",
    "    \n",
    "    inverted_lab_bgra_img = invert_img(input_dir=true_color_input_dir, \n",
    "                                       mask_dir=current_mask_dir)\n",
    "    # save images\n",
    "    cv2.imwrite(inverted_lab_output_dir, inverted_lab_bgra_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d54812-828b-4f66-9bb0-6f89d5a902da",
   "metadata": {},
   "source": [
    "# Refined Masks\n",
    "To this point we just separated the foreground from the background<br>\n",
    "However in the foreground might be some parts that we want to exclude (e.g., the green leaves on the tomato or the yellow seeds on the strawberry)<br>\n",
    "We do so, by getting the \"typical\" hue value of the image and exclude pixels that are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a7bbc6-b657-4281-ae34-5e07ffef885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mask_dir = os.path.join(stim_dir, 'color_masks')\n",
    "if not os.path.exists(color_mask_dir):\n",
    "    os.mkdir(color_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba746e8a-74a3-4e27-ab58-9c2d0a7378ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_mask(path, lower_threshold=0, upper_threshold=180):\n",
    "    '''This function loads an image and create a mask of all pixels that lie within the object in question, \n",
    "    are not pure white and lie within a hue range.\n",
    "    \n",
    "    Input \n",
    "    path: path to the image that needs to be masked\n",
    "    lower_threshold: lower threshold of the hue\n",
    "    upper_threshold: upper threshold of the hue\n",
    "    \n",
    "    Output: mask\n",
    "    \n",
    "    The function first creates a mask covering the object by drawing a contour around the largest non-white object \n",
    "    (getting rid of unwanted pixels in the periphery).\n",
    "    Since some images contain multiple objects that enclose a white surface the function create a second mask of \n",
    "    ALL white pixels.\n",
    "    \n",
    "    In a last step the function creates a mask of all pixels that lie within a range of hue values.\n",
    "    This way we avoid pixels making up the a structure of the object that has a different memory color\n",
    "    (e.g., yellow seeds in a strawberry)'''\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a binary mask for the largest contour\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "\n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    H,L,S = cv2.split(hls_img)\n",
    "\n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = L != 255\n",
    "\n",
    "    # Create a binary mask for pixels within the hue range\n",
    "    hue_mask = cv2.inRange(H, lower_threshold, upper_threshold)\n",
    "    \n",
    "    # combine all masks into one big mask\n",
    "    new_mask = white_mask & binary_mask & hue_mask\n",
    "    \n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5260c9e-1ab2-4999-b663-4325a59f74d2",
   "metadata": {},
   "source": [
    "#### Create the masks for the objects\n",
    "Visually inspecting the histogram plots in `../stimuli/analysis/hue_distributions`<br>\n",
    "Select the value deemed suitable and create the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0094b073-48f4-4cda-adb4-a762723491cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file containing upper and lower limits for the color hue threshold\n",
    "color_threshold_df = pd.read_csv(os.path.join(stim_dir, 'masking_thresholds.csv'))\n",
    "# iterate over dataframe and create new masks based on values\n",
    "for idx, item in color_threshold_df.iterrows():\n",
    "    path = os.path.join(true_color_stim_dir,item.Stimulus)\n",
    "    new_mask = create_color_mask(path=path, lower_threshold=item.lower, upper_threshold=item.upper)\n",
    "    # convert mask from bool to black and white\n",
    "    new_mask = new_mask.astype(np.uint8)*255\n",
    "    # make mask three dimensional (for the shine toolbox)\n",
    "    new_mask = cv2.cvtColor(new_mask, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite(os.path.join(color_mask_dir,item.Stimulus), new_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10faf42b-cd80-4323-855b-818da4ba0e82",
   "metadata": {},
   "source": [
    "### BLUE\n",
    "Green, red, orange and yellow stimuli were taken from Teichmann 2020 and share many properties<br>\n",
    "The blue stimuli however were taken from google searches and cannot be automatically separated into foreground an background as the other stimuli can<br>\n",
    "Inspect each of the blue stimuli by it self and try to find good parameters to separate them using `opencv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edb9816d-b194-4825-a1fb-7a2208ca1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blue_masks(R_channel,G_channel,B_channel, R_thresh, G_thresh, B_thresh):\n",
    "    _, thres_R = cv2.threshold(R, R_thresh[0], R_thresh[1], cv2.THRESH_BINARY_INV)\n",
    "    _, thres_G = cv2.threshold(G, G_thresh[0], G_thresh[1], cv2.THRESH_BINARY_INV)\n",
    "    _, thres_B = cv2.threshold(B, R_thresh[0], R_thresh[1], cv2.THRESH_BINARY_INV)\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    rgb_thres = cv2.merge((thres_R,thres_G,thres_B))\n",
    "    gray_thres = cv2.cvtColor(rgb_thres, cv2.COLOR_RGB2GRAY)\n",
    "    # # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(gray_thres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    mask = np.zeros(gray_thres.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = hls_img[:,:,1] != 255\n",
    "\n",
    "    big_mask = np.logical_and(white_mask, binary_mask)\n",
    "    return big_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2933b0a-b545-48f2-bb91-6dd15425d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NIVEA\n",
    "stim = 'blue_nivea.png'\n",
    "path = os.path.join(true_color_stim_dir,stim)\n",
    "img = cv2.imread(path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# RGB values of background are 71,112,76 - even though in the original png they are transparent\n",
    "print(img_rgb[0,0])\n",
    "r_threshold = [70,72]\n",
    "g_threshold = [111,113]\n",
    "b_threshold = [75,77]\n",
    "# create mask using these values to extract the background\n",
    "R, G, B = cv2.split(img_rgb)\n",
    "nivea_mask = create_blue_masks(R_channel=R, G_channel=G,B_channel=B,\n",
    "                               R_thresh=r_threshold,G_thresh=g_threshold,B_thresh=b_threshold)\n",
    "# make the mask an image with three channels either white or black\n",
    "nivea_mask_img = nivea_mask.astype(np.uint8)*255\n",
    "nivea_mask_img = cv2.cvtColor(nivea_mask_img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite(os.path.join(color_mask_dir,stim), nivea_mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d2d9400-b2a8-4145-a927-8c8eeae6e6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n",
      "[255 255 255]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POOL\n",
    "stim = 'blue_pool.png'\n",
    "path = os.path.join(true_color_stim_dir,stim)\n",
    "img = cv2.imread(path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# RGB values of background are 255,255,255 for white background squares\n",
    "print(img_rgb[0,0])\n",
    "# RGB values of background are 238,239,239 for gray background squares\n",
    "print(img_rgb[50,0])\n",
    "R, G, B = cv2.split(img_rgb)\n",
    "r_threshold = [237,255]\n",
    "g_threshold = [238,255]\n",
    "b_threshold = [238,255]\n",
    "pool_mask = create_blue_masks(R_channel=R, G_channel=G,B_channel=B,\n",
    "                              R_thresh=r_threshold,G_thresh=g_threshold,B_thresh=b_threshold)\n",
    "# make the mask an image with three channels either white or black\n",
    "pool_mask_img = pool_mask.astype(np.uint8)*255\n",
    "pool_mask_img = cv2.cvtColor(pool_mask_img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite(os.path.join(color_mask_dir,stim), pool_mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0f11be6-c52a-44e5-9047-a1b7eb93c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n",
      "[255 255 255]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIGN\n",
    "stim = 'blue_sign.png'\n",
    "path = os.path.join(true_color_stim_dir,stim)\n",
    "img = cv2.imread(path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# RGB values of background are 0,0,0 \n",
    "print(img_rgb[0,0])\n",
    "# RGB values of the circle and figures in the sign are white\n",
    "print(img_rgb[200,310])\n",
    "# get the grayscaled image and remove all white and black pixels\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "white_mask = gray_img != 255\n",
    "black_mask = gray_img != 0\n",
    "sign_mask = white_mask & black_mask\n",
    "# make the mask an image with three channels either white or black\n",
    "sign_mask_img = sign_mask.astype(np.uint8)*255\n",
    "sign_mask_img = cv2.cvtColor(sign_mask_img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite(os.path.join(color_mask_dir,stim), sign_mask_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e9d2e-72c3-4d31-b1de-bf9a8b57651b",
   "metadata": {},
   "source": [
    "### Refined inverted images\n",
    "In the previous steps we inverted the color of the whole object\n",
    "Now we create inverted images with the refined masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25b830e3-079e-44ac-9117-971365ca55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimuli in LAB space inverted\n",
    "refined_inverted_lab_stim_dir = os.path.join(stim_dir,'inverted_lab_masked')\n",
    "if not os.path.exists(refined_inverted_lab_stim_dir):\n",
    "    os.mkdir(refined_inverted_lab_stim_dir)\n",
    "\n",
    "for stim in stimuli:\n",
    "    # output directories\n",
    "    true_color_input_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    current_mask_dir = os.path.join(foreground_background_mask_dir, stim)\n",
    "    current_color_mask_dir = os.path.join(color_mask_dir,stim)\n",
    "    inverted_lab_output_dir = os.path.join(refined_inverted_lab_stim_dir, stim)\n",
    "    \n",
    "    inverted_lab_bgra_img = invert_img(input_dir=true_color_input_dir, \n",
    "                                       mask_dir=current_mask_dir,\n",
    "                                       refined_mask_dir=current_color_mask_dir)\n",
    "    # save images\n",
    "    cv2.imwrite(inverted_lab_output_dir, inverted_lab_bgra_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d603758-d701-4207-93d6-33e01370d38c",
   "metadata": {},
   "source": [
    "# Representative colors of stimuli\n",
    "For each stimulus get a representative pixel of the true color and invered color stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b2cb993-380f-4fe2-8489-74424546293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store results in\n",
    "rep_pixel_dict = {\n",
    "    'stimuli': [],\n",
    "    'true_R': [],\n",
    "    'true_G': [],\n",
    "    'true_B': [],\n",
    "    'inv_R': [],\n",
    "    'inv_G': [],\n",
    "    'inv_B': [],\n",
    "}\n",
    "\n",
    "stimulus_selection = [\n",
    "    'blue_nivea.png',\n",
    "    'blue_pool.png',\n",
    "    'blue_sign.png',\n",
    "    'green_brokkoli_1.png',\n",
    "    'green_frog_1.png',\n",
    "    'green_lettuce_1.png',\n",
    "    'orange_basketball.png',\n",
    "    'orange_carrots.png',\n",
    "    'orange_pumpkin.png',\n",
    "    'red_fire_extinguisher_1.png',\n",
    "    'red_strawberry.png',\n",
    "    'red_tomato.png',\n",
    "    'yellow_banana.png',\n",
    "    'yellow_chicken.png',\n",
    "    'yellow_corn.png'\n",
    "]\n",
    "\n",
    "for stim in stimulus_selection:\n",
    "    rep_pixel_dict['stimuli'].append(stim)\n",
    "    # get paths of stimuli\n",
    "    true_path = os.path.join(true_color_stim_dir,stim)\n",
    "    inv_path = os.path.join(inverted_lab_stim_dir,stim)\n",
    "    # read in the original and inverted stimuli\n",
    "    true_color_img = cv2.imread(true_path)\n",
    "    inv_color_img = cv2.imread(inv_path)\n",
    "    # convert the image from BRG (opencv default) to RGB (everybodies default)\n",
    "    true_color_img = cv2.cvtColor(true_color_img, cv2.COLOR_BGR2RGB)\n",
    "    inv_color_img = cv2.cvtColor(inv_color_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # read in the mask of the stimulus\n",
    "    mask_path = os.path.join(mask_dir, stim)\n",
    "    mask_img = cv2.imread(mask_path)\n",
    "    # the mask is saved as an image with three channels with either 0 or 255 values -> convert to boolean mask\n",
    "    mask_img = mask_img[:,:,0].astype(bool)\n",
    "    \n",
    "    # extract the pixels within the mask\n",
    "    true_pixels = true_color_img[mask_img==1]\n",
    "    inv_pixels = inv_color_img[mask_img==1]\n",
    "    \n",
    "    # get the representative pixel by searching for the pixel values appearing most often\n",
    "    # true pixel\n",
    "    # unique_colors, counts = np.unique(true_pixels,axis=0,return_counts=True)\n",
    "    # most_frequent_indices = np.flip(np.argsort(counts))\n",
    "    # # we need to convert the pixel from np.uint8 to int. Otherwise the transversion to the dataframe messes things up\n",
    "    # most_frequent_true_color = unique_colors[most_frequent_indices[0]].astype(int)\n",
    "    most_frequent_true_color = true_pixels.mean(axis=0)\n",
    "    rep_pixel_dict['true_R'].append(most_frequent_true_color[0])\n",
    "    rep_pixel_dict['true_G'].append(most_frequent_true_color[1])\n",
    "    rep_pixel_dict['true_B'].append(most_frequent_true_color[2])\n",
    "    \n",
    "    # inverted pixel\n",
    "    # unique_colors, counts = np.unique(inv_pixels,axis=0,return_counts=True)\n",
    "    # most_frequent_indices = np.flip(np.argsort(counts))\n",
    "    # # we need to convert the pixel from np.uint8 to int. Otherwise the transversion to the dataframe messes things up\n",
    "    # most_frequent_inverted_color = unique_colors[most_frequent_indices[0]].astype(int)\n",
    "    most_frequent_inverted_color = inv_pixels.mean(axis=0)\n",
    "    rep_pixel_dict['inv_R'].append(most_frequent_inverted_color[0])\n",
    "    rep_pixel_dict['inv_G'].append(most_frequent_inverted_color[1])\n",
    "    rep_pixel_dict['inv_B'].append(most_frequent_inverted_color[2])\n",
    "    \n",
    "# convert the dictionary to a dataframe\n",
    "pixel_df = pd.DataFrame(data=rep_pixel_dict, columns=rep_pixel_dict.keys())\n",
    "pixel_df.to_csv(os.path.join(stim_dir,'representative_pixels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0189cea7-efa8-4ba7-83b3-68db44982b21",
   "metadata": {},
   "source": [
    "#### an image of the colors for each hue value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e839c0b6-22e5-4369-ac64-a984c6135714",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = np.zeros((100,180,3),dtype='uint8')\n",
    "all_colors[:,:,0] = np.linspace(0,180,180)\n",
    "all_colors[:,:,1] = 100\n",
    "all_colors[:,:,2] = 150\n",
    "\n",
    "all_colors_rgb = cv2.cvtColor(all_colors, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(all_colors_rgb)\n",
    "plt.savefig(os.path.join(mask_dir,'hue_distribution.png'))\n",
    "plt.close(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a062fb-b11e-43c9-bacb-6b187c135cdd",
   "metadata": {},
   "source": [
    "### Luminance sanity check\n",
    "Changing the color in LAB space resulted in pixels not representable in RGB space.<br>\n",
    "In turn the conversion back results in different colors with different luminances<br>\n",
    "<br>\n",
    "Check the actual differences of luminance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29751c7a-ce0a-4b27-adac-9616c6bf0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lum_diff_dir = os.path.join(results_dir, 'lum_diff')\n",
    "if not os.path.exists(lum_diff_dir):\n",
    "    os.mkdir(lum_diff_dir)\n",
    "    \n",
    "lum_diff_sum = []\n",
    "lum_diff_percent = []\n",
    "\n",
    "for stim in stimuli:\n",
    "    true_path = os.path.join(true_color_stim_dir, stim)\n",
    "    inv_path = os.path.join(inverted_lab_stim_dir, stim)\n",
    "    mask_path = os.path.join(mask_dir, stim)\n",
    "    mask_img = cv2.imread(mask_path)\n",
    "    mask_img = mask_img[:,:,0].astype(bool)\n",
    "\n",
    "    true_color_img = cv2.imread(true_path)\n",
    "    true_lab = cv2.cvtColor(true_color_img, cv2.COLOR_BGR2LAB)\n",
    "    true_L, a, b = cv2.split(true_lab)\n",
    "    \n",
    "    inv_color_img = cv2.imread(inv_path)\n",
    "    inv_lab = cv2.cvtColor(inv_color_img, cv2.COLOR_BGR2LAB)\n",
    "    inv_L, a, b = cv2.split(inv_lab)\n",
    "\n",
    "    true_L_f = true_L.astype(np.float32)\n",
    "    inv_L_f = inv_L.astype(np.float32)\n",
    "    \n",
    "    lum_diff = (true_L_f-inv_L_f)[mask_img==1]\n",
    "    lum_diff_sum.append(lum_diff.sum())\n",
    "    lum_diff_percent.append(sum(lum_diff!=0)/len(lum_diff))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.hist(lum_diff, bins=40)\n",
    "    plt.savefig(os.path.join(lum_diff_dir,stim))\n",
    "    plt.close(fig=fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
