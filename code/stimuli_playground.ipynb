{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10b476b-2545-49f6-a022-01e596a0cb38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stimulus playground\n",
    "This script is a playground to inspect and manipulate stimuli for a binocular rivalry (BR) experiment<br>\n",
    "In this experiment (as at April th) I aim to present objects that are associated with a color (e.g., banana - yellow, strawberry - red) in rivarous situations.<br>\n",
    "1. Show the same stimulus either in the \"correct\" and in an \"incorrect\" color (a banana in yellow and blue)\n",
    "2. Show two different stimuli that are associated with different colors but in the same color (a banana and a strawberry both in yellow)\n",
    "\n",
    "Compare the onset and sustained dominance with rivaling gratings that follow a series of non-rivaling gratings that appear to be rotating (Denison et al., 2011, Attarha et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc02fc-718e-4157-8d1f-061c8c9abb16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stimuli\n",
    "In the following I will look at the stimuli used by Teichmann et al., 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f4fc70-b12f-4ea2-a00a-2a39b416d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# use the os\n",
    "import os\n",
    "import glob\n",
    "# math and data structure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# image processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17581e11-225f-4d53-a5b5-cc8468dea3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimuli from Teichmann et al., 2020\n",
    "# provided by her OSF site (https://osf.io/tcqjh/)\n",
    "stim_dir = os.path.join('..','stimuli')\n",
    "original_stim_dir = os.path.join(stim_dir,'original')\n",
    "grey_stim_dir = os.path.join(stim_dir,'grey') # not used yet\n",
    "# get a list of all stimuli in the directory\n",
    "stimuli_full_path = glob.glob(os.path.join(original_stim_dir,'*.png'))\n",
    "stimuli_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "stimuli = [os.path.basename(stim) for stim in stimuli_full_path]\n",
    "\n",
    "# taken from original - added alpha channel\n",
    "true_color_stim_dir = os.path.join(stim_dir,'true_color')\n",
    "# increased saturation for stimuli to prevent color fusion\n",
    "max_saturation_stim_dir = os.path.join(stim_dir,'max_saturation')\n",
    "if not os.path.exists(max_saturation_stim_dir):\n",
    "    os.mkdir(max_saturation_stim_dir)\n",
    "# stimuli in HLS space inverted\n",
    "inverted_hue_stim_dir = os.path.join(stim_dir,'inverted_hue')\n",
    "if not os.path.exists(inverted_hue_stim_dir):\n",
    "    os.mkdir(inverted_hue_stim_dir)\n",
    "# stimuli in LAB space inverted\n",
    "inverted_lab_stim_dir = os.path.join(stim_dir,'inverted_lab')\n",
    "if not os.path.exists(inverted_lab_stim_dir):\n",
    "    os.mkdir(inverted_lab_stim_dir)\n",
    "# stimuli in LUV space inverted\n",
    "inverted_luv_stim_dir = os.path.join(stim_dir,'inverted_luv')\n",
    "if not os.path.exists(inverted_luv_stim_dir):\n",
    "    os.mkdir(inverted_luv_stim_dir)\n",
    "    \n",
    "# where results of image analyses are saved\n",
    "results_dir = os.path.join(stim_dir,'analysis')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "ab_dist_plot_dir = os.path.join(results_dir, 'ab_distance')\n",
    "if not os.path.exists(ab_dist_plot_dir):\n",
    "    os.mkdir(ab_dist_plot_dir)\n",
    "uv_dist_plot_dir = os.path.join(results_dir, 'uv_distance')\n",
    "if not os.path.exists(uv_dist_plot_dir):\n",
    "    os.mkdir(uv_dist_plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "75f6fc7c-75b2-448b-b586-9a46e0a71d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read out the original stimuli and remove the background\n",
    "for stim_path, stim in zip(stimuli_full_path, stimuli):\n",
    "    # output directories\n",
    "    true_color_output_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(stim_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a binary mask for the largest contour\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "    \n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = hls_img[:,:,1]==255\n",
    "    big_mask = np.logical_or(white_mask, ~binary_mask)\n",
    "    \n",
    "    # add alpha channel to original image by converting from BGR to BGRA space\n",
    "    bgra_img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # change alpha channel of all pixels that are white to completely transparent\n",
    "    # CAUTION this results in pixels that are part of the stimulus to be transparent. \n",
    "    bgra_img[big_mask == 1] -= np.array([0,0,0,255],dtype='uint8') \n",
    "    cv2.imwrite(true_color_output_dir,bgra_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5a728-2bd2-49f8-b43b-a7485dd42c87",
   "metadata": {},
   "source": [
    "## Invert the color in the stimuli\n",
    "This is not performed in the same step because some minor adjustments were made in the true color stimuli using GIMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9f9bbb-e37d-4fc8-b631-d574616bea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(dim1, dim2, mask):\n",
    "    # Extract the values from dim1 and dim2 where mask is 0\n",
    "    dim1_flat = dim1[mask == 0]\n",
    "    dim2_flat = dim2[mask == 0]\n",
    "    # Stack the extracted values column-wise to form a 2D array\n",
    "    true_dims = np.column_stack((dim1_flat,dim2_flat)).astype('uint8')\n",
    "\n",
    "    # Invert dim1 and dim2 using 255 - dim\n",
    "    dim1_inv = 255 - dim1\n",
    "    dim2_inv = 255 - dim2\n",
    "    # Extract the inverted values from dim1_inv and dim2_inv where mask is 0\n",
    "    dim1_inv_flat = dim1_inv[mask == 0]\n",
    "    dim2_inv_flat = dim2_inv[mask == 0]\n",
    "    # Stack the extracted inverted values column-wise to form a 2D array\n",
    "    inv_dims = np.column_stack((dim1_inv_flat, dim2_inv_flat)).astype(int)\n",
    "\n",
    "    # Compute the Euclidean distance between each pair of points in true_dims and inv_dims\n",
    "    distances = np.sqrt((true_dims-inv_dims)**2).sum(axis=1)\n",
    "    \n",
    "    # Return the computed distances\n",
    "    return distances\n",
    "\n",
    "my_dict = {\n",
    "    'stim': stimuli,\n",
    "    'min_uv_dist': [],\n",
    "    'max_uv_dist': [],\n",
    "    'mean_uv_dist': [],\n",
    "    'median_uv_dist': [],\n",
    "    'min_ab_dist': [],\n",
    "    'max_ab_dist': [],\n",
    "    'mean_ab_dist': [],\n",
    "    'median_ab_dist': []\n",
    "}\n",
    "\n",
    "for stim in stimuli:\n",
    "    # output directories\n",
    "    true_color_input_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    max_saturation_output_dir = os.path.join(max_saturation_stim_dir, stim)\n",
    "    inverted_hue_output_dir = os.path.join(inverted_hue_stim_dir, stim)\n",
    "    inverted_lab_output_dir = os.path.join(inverted_lab_stim_dir, stim)\n",
    "    inverted_luv_output_dir = os.path.join(inverted_luv_stim_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(true_color_input_dir)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a binary mask for the largest contour\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "    \n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    # increase saturation \n",
    "    H,L,S = cv2.split(hls_img)\n",
    "    S_high = S + 255 - S.max()\n",
    "    hls_img = cv2.merge((H,L,S_high))\n",
    "    # create image with max saturation values\n",
    "    max_saturation_img = cv2.cvtColor(hls_img,cv2.COLOR_HLS2BGR)\n",
    "    # convert into LAB and LUV space for inversion\n",
    "    lab_img = cv2.cvtColor(max_saturation_img, cv2.COLOR_BGR2LAB)\n",
    "    luv_img = cv2.cvtColor(max_saturation_img, cv2.COLOR_BGR2LUV)\n",
    "    \n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = hls_img[:,:,1]==255\n",
    "    big_mask = np.logical_or(white_mask, ~binary_mask)\n",
    "    # create a copy of the hls_img and invert the hue\n",
    "    inverted_hls_img = np.copy(hls_img)\n",
    "    # select all pixels that are not white and increase the hue value by 90 (hue ranges from 0-179)\n",
    "    inverted_hls_img[np.where(binary_mask != 0)]+=np.array([90,0,0],dtype='uint8')\n",
    "    # Split the L*a*b* image into its channels\n",
    "    L, a, b = cv2.split(lab_img)\n",
    "    # Invert the a and b channels\n",
    "    a_inv = 255 - a\n",
    "    b_inv = 255 - b\n",
    "    \n",
    "    # get distances\n",
    "    ab_distances = calc_dist(a,b,big_mask)\n",
    "    my_dict['min_ab_dist'].append(ab_distances.min())\n",
    "    my_dict['max_ab_dist'].append(ab_distances.max())\n",
    "    my_dict['mean_ab_dist'].append(ab_distances.mean())\n",
    "    my_dict['median_ab_dist'].append(np.median(ab_distances))\n",
    "    \n",
    "    # plot histogram of distances\n",
    "    fig = plt.figure()\n",
    "    plt.hist(ab_distances,bins=50)\n",
    "    plt.savefig(os.path.join(ab_dist_plot_dir,stim))\n",
    "    plt.close(fig=fig)\n",
    "\n",
    "    # Merge the inverted channels back into the L*a*b* image\n",
    "    inverted_lab_img = cv2.merge((L, a_inv, b_inv))\n",
    "    \n",
    "    # do the same for LUV space\n",
    "    L, u, v = cv2.split(luv_img)\n",
    "    u_inv = 255 - u\n",
    "    v_inv = 255 - v\n",
    "    \n",
    "    uv_distances = calc_dist(u,v,big_mask)\n",
    "    my_dict['min_uv_dist'].append(uv_distances.min())\n",
    "    my_dict['max_uv_dist'].append(uv_distances.max())\n",
    "    my_dict['mean_uv_dist'].append(uv_distances.mean())\n",
    "    my_dict['median_uv_dist'].append(np.median(uv_distances))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.hist(uv_distances,bins=50)\n",
    "    plt.savefig(os.path.join(uv_dist_plot_dir,stim))\n",
    "    plt.close(fig=fig)\n",
    "    \n",
    "    inverted_luv_img = cv2.merge((L, u_inv, v_inv))\n",
    "    \n",
    "    # convert inverted images image back into BGR \n",
    "    inverted_hue_bgr_img = cv2.cvtColor(inverted_hls_img, cv2.COLOR_HLS2BGR)\n",
    "    inverted_lab_bgr_img = cv2.cvtColor(inverted_lab_img, cv2.COLOR_LAB2BGR)\n",
    "    inverted_luv_bgr_img = cv2.cvtColor(inverted_luv_img, cv2.COLOR_LUV2BGR)\n",
    "    \n",
    "    # add alpha channel to inverted image by converting from BGR to BGRA space\n",
    "    max_saturation_bgra_img = cv2.cvtColor(max_saturation_img, cv2.COLOR_BGR2BGRA)\n",
    "    inverted_hue_bgra_img = cv2.cvtColor(inverted_hue_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    inverted_lab_bgra_img = cv2.cvtColor(inverted_lab_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    inverted_luv_bgra_img = cv2.cvtColor(inverted_luv_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # make background (everything outside the mask) transparent\n",
    "    max_saturation_bgra_img[big_mask == 1] -= np.array([0,0,0,255],dtype='uint8')\n",
    "    inverted_hue_bgra_img[big_mask == 1] -= np.array([0,0,0,255],dtype='uint8')\n",
    "    inverted_lab_bgra_img[big_mask == 1] -= np.array([0,0,0,255],dtype='uint8')\n",
    "    inverted_luv_bgra_img[big_mask == 1] -= np.array([0,0,0,255],dtype='uint8')\n",
    "    \n",
    "    # save images\n",
    "    cv2.imwrite(max_saturation_output_dir, max_saturation_bgra_img)\n",
    "    cv2.imwrite(inverted_hue_output_dir, inverted_hue_bgra_img)\n",
    "    cv2.imwrite(inverted_lab_output_dir, inverted_lab_bgra_img)\n",
    "    cv2.imwrite(inverted_luv_output_dir, inverted_luv_bgra_img)\n",
    "    \n",
    "# save information about distances\n",
    "my_df = pd.DataFrame(data=my_dict,columns=my_dict.keys())\n",
    "my_df.to_csv(os.path.join(results_dir,'color_distances.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba746e8a-74a3-4e27-ab58-9c2d0a7378ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = 'green_frog_2.png'\n",
    "\n",
    "true_color_input_dir = os.path.join(true_color_stim_dir, stim)\n",
    "inverted_hue_output_dir = os.path.join(inverted_hue_stim_dir, stim)\n",
    "inverted_lab_output_dir = os.path.join(inverted_lab_stim_dir, stim)\n",
    "inverted_luv_output_dir = os.path.join(inverted_luv_stim_dir, stim)\n",
    "\n",
    "# read in the original image\n",
    "img = cv2.imread(true_color_input_dir)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to isolate the non-white pixels\n",
    "_, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find the contours in the thresholded image\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find the contour with the largest area\n",
    "largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Create a binary mask for the largest contour\n",
    "mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "# Create a binary mask with the pixels inside the contour set to white\n",
    "# and the pixels outside the contour set to black\n",
    "binary_mask = cv2.inRange(mask, 255, 255)\n",
    "\n",
    "# convert image from BGR to HLS space\n",
    "hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "H,L,S = cv2.split(hls_img)\n",
    "S_high = S + 255 - S.max()\n",
    "hls_img = cv2.merge((H,L,S_high))\n",
    "img = cv2.cvtColor(hls_img,cv2.COLOR_HLS2BGR)\n",
    "lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "luv_img = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "\n",
    "# The contour also captures empty space surrounded by object boundaries\n",
    "# We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "white_mask = hls_img[:,:,1]==255\n",
    "big_mask = np.logical_or(white_mask, ~binary_mask)\n",
    "\n",
    "L, a, b = cv2.split(lab_img)\n",
    "# Invert the a and b channels\n",
    "a_inv = 255 - a\n",
    "b_inv = 255 - b\n",
    "\n",
    "inverted_img = cv2.merge((L, a_inv, b_inv))\n",
    "bgr_inv = cv2.cvtColor(inverted_img, cv2.COLOR_LUV2BGR)\n",
    "bgra_inv = cv2.cvtColor(bgr_inv, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "bgra = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA)\n",
    "bgra[big_mask == 1] -= np.array([0,0,0,255],dtype='uint8')\n",
    "bgra_inv[big_mask == 1] -= np.array([0,0,0,255],dtype='uint8')\n",
    "\n",
    "# Convert the a and b channels to float32\n",
    "a = np.float32(a)\n",
    "b = np.float32(b)\n",
    "\n",
    "# Compute the magnitude and angle of the a-b vectors\n",
    "magnitude, angle = cv2.cartToPolar(a, b, angleInDegrees=True)\n",
    "# Normalize the angle values to the range [0, 1]\n",
    "angle_norm = cv2.normalize(angle, None, 0, 1, cv2.NORM_MINMAX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
