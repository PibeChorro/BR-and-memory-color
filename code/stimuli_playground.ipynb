{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10b476b-2545-49f6-a022-01e596a0cb38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stimulus playground\n",
    "This script is a playground to inspect and manipulate stimuli for a binocular rivalry (BR) experiment<br>\n",
    "In this experiment (as at April th) I aim to present objects that are associated with a color (e.g., banana - yellow, strawberry - red) in rivarous situations.<br>\n",
    "1. Show the same stimulus either in the \"correct\" and in an \"incorrect\" color (a banana in yellow and blue)\n",
    "2. Show two different stimuli that are associated with different colors but in the same color (a banana and a strawberry both in yellow)\n",
    "\n",
    "Compare the onset and sustained dominance with rivaling gratings that follow a series of non-rivaling gratings that appear to be rotating (Denison et al., 2011, Attarha et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc02fc-718e-4157-8d1f-061c8c9abb16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stimuli\n",
    "In the following I will look at the stimuli used by Teichmann et al., 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f4fc70-b12f-4ea2-a00a-2a39b416d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# use the os\n",
    "import os\n",
    "import glob\n",
    "# math and data structure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# image processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "17581e11-225f-4d53-a5b5-cc8468dea3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimuli from Teichmann et al., 2020\n",
    "# provided by her OSF site (https://osf.io/tcqjh/)\n",
    "stim_dir = os.path.join('..','stimuli')\n",
    "original_stim_dir = os.path.join(stim_dir,'original')\n",
    "grey_stim_dir = os.path.join(stim_dir,'grey') # not used yet\n",
    "# get a list of all stimuli in the directory\n",
    "stimuli_full_path = glob.glob(os.path.join(original_stim_dir,'*.png'))\n",
    "stimuli_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "stimuli = [os.path.basename(stim) for stim in stimuli_full_path]\n",
    "\n",
    "# taken from original - added alpha channel\n",
    "true_color_stim_dir = os.path.join(stim_dir,'true_color')\n",
    "# increased saturation for stimuli to prevent color fusion\n",
    "max_saturation_stim_dir = os.path.join(stim_dir,'max_saturation')\n",
    "if not os.path.exists(max_saturation_stim_dir):\n",
    "    os.mkdir(max_saturation_stim_dir)\n",
    "min_saturation_stim_dir = os.path.join(stim_dir,'min_saturation')\n",
    "if not os.path.exists(min_saturation_stim_dir):\n",
    "    os.mkdir(min_saturation_stim_dir)\n",
    "# stimuli in HLS space inverted\n",
    "inverted_hue_stim_dir = os.path.join(stim_dir,'inverted_hue')\n",
    "if not os.path.exists(inverted_hue_stim_dir):\n",
    "    os.mkdir(inverted_hue_stim_dir)\n",
    "# stimuli in LAB space inverted\n",
    "inverted_lab_stim_dir = os.path.join(stim_dir,'inverted_lab')\n",
    "if not os.path.exists(inverted_lab_stim_dir):\n",
    "    os.mkdir(inverted_lab_stim_dir)\n",
    "# stimuli in LUV space inverted\n",
    "inverted_luv_stim_dir = os.path.join(stim_dir,'inverted_luv')\n",
    "if not os.path.exists(inverted_luv_stim_dir):\n",
    "    os.mkdir(inverted_luv_stim_dir)\n",
    "# masks\n",
    "mask_dir = os.path.join(stim_dir,'masks')\n",
    "if not os.path.exists(mask_dir):\n",
    "    os.mkdir(mask_dir)\n",
    "shine_dir = os.path.join(stim_dir,'shine_toolbox')\n",
    "compressed_true_color = os.path.join(stim_dir, 'compressed_true_color')\n",
    "if not os.path.exists(compressed_true_color):\n",
    "    os.mkdir(compressed_true_color)\n",
    "compressed_false_color = os.path.join(stim_dir, 'compressed_false_color')\n",
    "if not os.path.exists(compressed_false_color):\n",
    "    os.mkdir(compressed_false_color)\n",
    "    \n",
    "    \n",
    "# where results of image analyses are saved\n",
    "results_dir = os.path.join(stim_dir,'analysis')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "ab_dist_plot_dir = os.path.join(results_dir, 'ab_distance')\n",
    "if not os.path.exists(ab_dist_plot_dir):\n",
    "    os.mkdir(ab_dist_plot_dir)\n",
    "uv_dist_plot_dir = os.path.join(results_dir, 'uv_distance')\n",
    "if not os.path.exists(uv_dist_plot_dir):\n",
    "    os.mkdir(uv_dist_plot_dir)\n",
    "hue_dist_plot_dir = os.path.join(results_dir, 'hue_distributions')\n",
    "if not os.path.exists(hue_dist_plot_dir):\n",
    "    os.mkdir(hue_dist_plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004866c-20e4-48c5-9c7c-538d1eb23921",
   "metadata": {},
   "source": [
    "### Note\n",
    "Some of the stimuli taken from Teichmann were prepared with the following cell, but created \"wholes\" in the stimuli, because these had pure white pixels in the foreground.<br>\n",
    "The \"wholes\" within the images were filled using GIMP and replaced the originals.<br>\n",
    "The true originals that were replaced are now located in `original_exchanged`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "75f6fc7c-75b2-448b-b586-9a46e0a71d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read out the original stimuli and remove the background\n",
    "for stim_path, stim in zip(stimuli_full_path, stimuli):\n",
    "    # output directories\n",
    "    true_color_output_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(stim_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a binary mask for the largest contour\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "    \n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = hls_img[:,:,1]==255\n",
    "    big_mask = np.logical_or(white_mask, ~binary_mask)\n",
    "    \n",
    "    # add alpha channel to original image by converting from BGR to BGRA space\n",
    "    bgra_img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # change alpha channel of all pixels that are white to completely transparent\n",
    "    # CAUTION this results in pixels that are part of the stimulus to be transparent. \n",
    "    bgra_img[big_mask == 1] = np.array([255,255,255,0],dtype='uint8') \n",
    "    cv2.imwrite(true_color_output_dir,bgra_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5a728-2bd2-49f8-b43b-a7485dd42c87",
   "metadata": {},
   "source": [
    "## Invert the color in the stimuli\n",
    "This is not performed in the same step because some minor adjustments were made in the true color stimuli using GIMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5a9f9bbb-e37d-4fc8-b631-d574616bea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(dim1, dim2, mask):\n",
    "    # Extract the values from dim1 and dim2 where mask is 0\n",
    "    dim1_flat = dim1[~mask]\n",
    "    dim2_flat = dim2[~mask]\n",
    "    # Stack the extracted values column-wise to form a 2D array\n",
    "    true_dims = np.column_stack((dim1_flat,dim2_flat)).astype('uint8')\n",
    "\n",
    "    # Invert dim1 and dim2 using 255 - dim\n",
    "    dim1_inv = 255 - dim1\n",
    "    dim2_inv = 255 - dim2\n",
    "    # Extract the inverted values from dim1_inv and dim2_inv where mask is 0\n",
    "    dim1_inv_flat = dim1_inv[~mask]\n",
    "    dim2_inv_flat = dim2_inv[~mask]\n",
    "    # Stack the extracted inverted values column-wise to form a 2D array\n",
    "    inv_dims = np.column_stack((dim1_inv_flat, dim2_inv_flat)).astype(int)\n",
    "\n",
    "    # Compute the Euclidean distance between each pair of points in true_dims and inv_dims\n",
    "    distances = np.sqrt((true_dims-inv_dims)**2).sum(axis=1)\n",
    "    \n",
    "    # Return the computed distances\n",
    "    return distances\n",
    "\n",
    "stimuli_full_path = glob.glob(os.path.join(true_color_stim_dir,'*.png'))\n",
    "stimuli_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "stimuli = [os.path.basename(stim) for stim in stimuli_full_path]\n",
    "\n",
    "my_dict = {\n",
    "    'stim': stimuli,\n",
    "    'min_uv_dist': [],\n",
    "    'max_uv_dist': [],\n",
    "    'mean_uv_dist': [],\n",
    "    'median_uv_dist': [],\n",
    "    'min_ab_dist': [],\n",
    "    'max_ab_dist': [],\n",
    "    'mean_ab_dist': [],\n",
    "    'median_ab_dist': []\n",
    "}\n",
    "\n",
    "for stim in stimuli:\n",
    "    # output directories\n",
    "    true_color_input_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    max_saturation_output_dir = os.path.join(max_saturation_stim_dir, stim)\n",
    "    min_saturation_output_dir = os.path.join(min_saturation_stim_dir, stim)\n",
    "    inverted_hue_output_dir = os.path.join(inverted_hue_stim_dir, stim)\n",
    "    inverted_lab_output_dir = os.path.join(inverted_lab_stim_dir, stim)\n",
    "    inverted_luv_output_dir = os.path.join(inverted_luv_stim_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(true_color_input_dir)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a binary mask for the largest contour\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "    \n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    # convert into LAB and LUV space for inversion\n",
    "    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    luv_img = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    \n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = hls_img[:,:,1] != 255\n",
    "    # black_mask = hls_img[:,:,1]==0\n",
    "    big_mask = np.logical_and(white_mask, binary_mask)\n",
    "    \n",
    "    # save the big mask\n",
    "    big_mask_img = big_mask.astype(np.uint8)*255\n",
    "    big_mask_img = cv2.cvtColor(big_mask_img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite(os.path.join(mask_dir,stim), big_mask_img)\n",
    "    \n",
    "    # increase saturation \n",
    "    H,L,S = cv2.split(hls_img)\n",
    "    S_high = S + 255 - S[big_mask].max()\n",
    "    S_low = S - S.min()\n",
    "    hls_img = cv2.merge((H,L,S_high))\n",
    "    hls_low_img = cv2.merge((H,L,S_low))\n",
    "    # create image with max saturation values\n",
    "    max_saturation_img = cv2.cvtColor(hls_img,cv2.COLOR_HLS2BGR)\n",
    "    min_saturation_img = cv2.cvtColor(hls_low_img,cv2.COLOR_HLS2BGR)\n",
    "    \n",
    "    # create a histogram of the hue values in the image for later mask creation\n",
    "    fig = plt.figure()\n",
    "    plt.hist(H[big_mask],bins=50)\n",
    "    plt.savefig(os.path.join(hue_dist_plot_dir,stim))\n",
    "    plt.close(fig=fig)\n",
    "\n",
    "    # create a copy of the hls_img and invert the hue\n",
    "    inverted_hls_img = np.copy(hls_img)\n",
    "    # select all pixels that are not white and increase the hue value by 90 (hue ranges from 0-179)\n",
    "    inverted_hls_img[np.where(binary_mask != 0)]+=np.array([90,0,0],dtype='uint8')\n",
    "    # Split the L*a*b* image into its channels\n",
    "    L, a, b = cv2.split(lab_img)\n",
    "    # Invert the a and b channels\n",
    "    a_inv = 255 - a\n",
    "    b_inv = 255 - b\n",
    "    \n",
    "    # get distances\n",
    "    # ab_distances = calc_dist(a,b,big_mask)\n",
    "    # my_dict['min_ab_dist'].append(ab_distances.min())\n",
    "    # my_dict['max_ab_dist'].append(ab_distances.max())\n",
    "    # my_dict['mean_ab_dist'].append(ab_distances.mean())\n",
    "    # my_dict['median_ab_dist'].append(np.median(ab_distances))\n",
    "    \n",
    "    # plot histogram of distances\n",
    "    # fig = plt.figure()\n",
    "    # plt.hist(ab_distances,bins=50)\n",
    "    # plt.savefig(os.path.join(ab_dist_plot_dir,stim))\n",
    "    # plt.close(fig=fig)\n",
    "\n",
    "    # Merge the inverted channels back into the L*a*b* image\n",
    "    inverted_lab_img = cv2.merge((L, a_inv, b_inv))\n",
    "    \n",
    "    # do the same for LUV space\n",
    "    L, u, v = cv2.split(luv_img)\n",
    "    u_inv = 255 - u\n",
    "    v_inv = 255 - v\n",
    "    \n",
    "    # uv_distances = calc_dist(u,v,big_mask)\n",
    "    # my_dict['min_uv_dist'].append(uv_distances.min())\n",
    "    # my_dict['max_uv_dist'].append(uv_distances.max())\n",
    "    # my_dict['mean_uv_dist'].append(uv_distances.mean())\n",
    "    # my_dict['median_uv_dist'].append(np.median(uv_distances))\n",
    "    \n",
    "    # fig = plt.figure()\n",
    "    # plt.hist(uv_distances,bins=50)\n",
    "    # plt.savefig(os.path.join(uv_dist_plot_dir,stim))\n",
    "    # plt.close(fig=fig)\n",
    "    \n",
    "    inverted_luv_img = cv2.merge((L, u_inv, v_inv))\n",
    "    \n",
    "    # convert inverted images image back into BGR \n",
    "    inverted_hue_bgr_img = cv2.cvtColor(inverted_hls_img, cv2.COLOR_HLS2BGR)\n",
    "    inverted_lab_bgr_img = cv2.cvtColor(inverted_lab_img, cv2.COLOR_LAB2BGR)\n",
    "    inverted_luv_bgr_img = cv2.cvtColor(inverted_luv_img, cv2.COLOR_LUV2BGR)\n",
    "    \n",
    "    # add alpha channel to inverted image by converting from BGR to BGRA space\n",
    "    max_saturation_bgra_img = cv2.cvtColor(max_saturation_img, cv2.COLOR_BGR2BGRA)\n",
    "    min_saturation_bgra_img = cv2.cvtColor(min_saturation_img, cv2.COLOR_BGR2BGRA)\n",
    "    inverted_hue_bgra_img = cv2.cvtColor(inverted_hue_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    inverted_lab_bgra_img = cv2.cvtColor(inverted_lab_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    inverted_luv_bgra_img = cv2.cvtColor(inverted_luv_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # make background (everything outside the mask) transparent (and white)\n",
    "    max_saturation_bgra_img[~big_mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    min_saturation_bgra_img[~big_mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    inverted_hue_bgra_img[~big_mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    inverted_lab_bgra_img[~big_mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    inverted_luv_bgra_img[~big_mask] = np.array([255,255,255,0],dtype='uint8')\n",
    "    \n",
    "    # save images\n",
    "    cv2.imwrite(max_saturation_output_dir, max_saturation_bgra_img)\n",
    "    cv2.imwrite(min_saturation_output_dir, min_saturation_bgra_img)\n",
    "    cv2.imwrite(inverted_hue_output_dir, inverted_hue_bgra_img)\n",
    "    cv2.imwrite(inverted_lab_output_dir, inverted_lab_bgra_img)\n",
    "    cv2.imwrite(inverted_luv_output_dir, inverted_luv_bgra_img)\n",
    "    \n",
    "# save information about distances\n",
    "# my_df = pd.DataFrame(data=my_dict,columns=my_dict.keys())\n",
    "# my_df.to_csv(os.path.join(results_dir,'color_distances.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38859f0e-802d-474f-9bce-babd31d3c588",
   "metadata": {},
   "source": [
    "## Masks\n",
    "Create masks that can later be used to _either_ add a hue to a gray-scaled image (two hues can be used gained from the equiluminant flicker method) _or_ as masks to the MATLAB _SHINE_ toolbox<br>\n",
    "We extract everything that is white and everything that lies outside of the \"typical\" color from the object.\n",
    "Gained by selecting (manually) the hue range we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ba746e8a-74a3-4e27-ab58-9c2d0a7378ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_mask(path, lower_threshold=0, upper_threshold=180):\n",
    "    '''This function loads an image and create a mask of all pixels that lie within the object in question, \n",
    "    are not pure white and lie within a hue range.\n",
    "    \n",
    "    Input \n",
    "    path: path to the image that needs to be masked\n",
    "    lower_threshold: lower threshold of the hue\n",
    "    upper_threshold: upper threshold of the hue\n",
    "    \n",
    "    Output: mask\n",
    "    \n",
    "    The function first creates a mask covering the object by drawing a contour around the largest non-white object \n",
    "    (getting rid of unwanted pixels in the periphery).\n",
    "    Since some images contain multiple objects that enclose a white surface the function create a second mask of \n",
    "    ALL white pixels.\n",
    "    \n",
    "    In a last step the function creates a mask of all pixels that lie within a range of hue values.\n",
    "    This way we avoid pixels making up the a structure of the object that has a different memory color\n",
    "    (e.g., yellow seeds in a strawberry)'''\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to isolate the non-white pixels\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a binary mask for the largest contour\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Create a binary mask with the pixels inside the contour set to white\n",
    "    # and the pixels outside the contour set to black\n",
    "    binary_mask = cv2.inRange(mask, 255, 255)\n",
    "\n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    H,L,S = cv2.split(hls_img)\n",
    "\n",
    "    # The contour also captures empty space surrounded by object boundaries\n",
    "    # We therefore add a mask that includes all pixels with a luminance value of 255 -> white\n",
    "    white_mask = L != 255\n",
    "\n",
    "    # Create a binary mask for pixels within the hue range\n",
    "    hue_mask = cv2.inRange(H, lower_threshold, upper_threshold)\n",
    "    \n",
    "    # combine all masks into one big mask\n",
    "    new_mask = white_mask & binary_mask & hue_mask\n",
    "    \n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5542ba8-e55a-4df7-be2a-3767bb28465e",
   "metadata": {},
   "source": [
    "#### Create the masks for the objects\n",
    "Visually inspecting the histogram plots in `../stimuli/analysis/hue_distributions`<br>\n",
    "Select the value deemed suitable and create the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0094b073-48f4-4cda-adb4-a762723491cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file containing upper and lower limits for the color hue threshold\n",
    "color_threshold_df = pd.read_csv(os.path.join(stim_dir, 'masking_thresholds.csv'))\n",
    "# iterate over dataframe and create new masks based on values\n",
    "for idx, item in color_threshold_df.iterrows():\n",
    "    path = os.path.join(true_color_stim_dir,item.Stimulus)\n",
    "    new_mask = create_color_mask(path=path, lower_threshold=item.lower, upper_threshold=item.upper)\n",
    "    # convert mask from bool to black and white\n",
    "    new_mask = new_mask.astype(np.uint8)*255\n",
    "    # make mask three dimensional (for the shine toolbox)\n",
    "    new_mask = cv2.cvtColor(new_mask, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite(os.path.join(mask_dir,item.Stimulus), new_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b967f-23fc-4dac-9cdd-aa43c480510e",
   "metadata": {},
   "source": [
    "### Luminance sanity check\n",
    "Changing the color in LAB space resulted in pixels not representable in RGB space.<br>\n",
    "In turn the conversion back results in different colors with different luminances<br>\n",
    "<br>\n",
    "Check the actual differences of luminance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29751c7a-ce0a-4b27-adac-9616c6bf0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lum_diff_dir = os.path.join(results_dir, 'lum_diff')\n",
    "if not os.path.exists(lum_diff_dir):\n",
    "    os.mkdir(lum_diff_dir)\n",
    "    \n",
    "lum_diff_sum = []\n",
    "lum_diff_percent = []\n",
    "\n",
    "for stim in stimuli:\n",
    "    true_path = os.path.join(true_color_stim_dir, stim)\n",
    "    inv_path = os.path.join(inverted_lab_stim_dir, stim)\n",
    "    mask_path = os.path.join(mask_dir, stim)\n",
    "    mask_img = cv2.imread(mask_path)\n",
    "    mask_img = mask_img[:,:,0].astype(bool)\n",
    "\n",
    "    true_color_img = cv2.imread(true_path)\n",
    "    true_lab = cv2.cvtColor(true_color_img, cv2.COLOR_BGR2LAB)\n",
    "    true_L, a, b = cv2.split(true_lab)\n",
    "    \n",
    "    inv_color_img = cv2.imread(inv_path)\n",
    "    inv_lab = cv2.cvtColor(inv_color_img, cv2.COLOR_BGR2LAB)\n",
    "    inv_L, a, b = cv2.split(inv_lab)\n",
    "\n",
    "    true_L_f = true_L.astype(np.float32)\n",
    "    inv_L_f = inv_L.astype(np.float32)\n",
    "    \n",
    "    lum_diff = (true_L_f-inv_L_f)[mask_img==1]\n",
    "    lum_diff_sum.append(lum_diff.sum())\n",
    "    lum_diff_percent.append(sum(lum_diff!=0)/len(lum_diff))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.hist(lum_diff, bins=40)\n",
    "    plt.savefig(os.path.join(lum_diff_dir,stim))\n",
    "    plt.close(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d603758-d701-4207-93d6-33e01370d38c",
   "metadata": {},
   "source": [
    "# Example color values for flicker method\n",
    "For each stimulus get a representative pixel of the true color and invered color stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4b2cb993-380f-4fe2-8489-74424546293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store results in\n",
    "rep_pixel_dict = {\n",
    "    'stimuli': [],\n",
    "    'true_R': [],\n",
    "    'true_G': [],\n",
    "    'true_B': [],\n",
    "    'inv_R': [],\n",
    "    'inv_G': [],\n",
    "    'inv_B': [],\n",
    "}\n",
    "\n",
    "for stim in stimuli:\n",
    "    rep_pixel_dict['stimuli'].append(stim)\n",
    "    # get paths of stimuli\n",
    "    true_path = os.path.join(true_color_stim_dir,stim)\n",
    "    inv_path = os.path.join(inverted_lab_stim_dir,stim)\n",
    "    # read in the original and inverted stimuli\n",
    "    true_color_img = cv2.imread(true_path)\n",
    "    inv_color_img = cv2.imread(inv_path)\n",
    "    # convert the image from BRG (opencv default) to RGB (everybodies default)\n",
    "    true_color_img = cv2.cvtColor(true_color_img, cv2.COLOR_BGR2RGB)\n",
    "    inv_color_img = cv2.cvtColor(inv_color_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # read in the mask of the stimulus\n",
    "    mask_path = os.path.join(mask_dir, stim)\n",
    "    mask_img = cv2.imread(mask_path)\n",
    "    # the mask is saved as an image with three channels with either 0 or 255 values -> convert to boolean mask\n",
    "    mask_img = mask_img[:,:,0].astype(bool)\n",
    "    \n",
    "    # extract the pixels within the mask\n",
    "    true_pixels = true_color_img[mask_img==1]\n",
    "    inv_pixels = inv_color_img[mask_img==1]\n",
    "    \n",
    "    # get the representative pixel by searching for the pixel values appearing most often\n",
    "    # true pixel\n",
    "    unique_colors, counts = np.unique(true_pixels,axis=0,return_counts=True)\n",
    "    most_frequent_indices = np.flip(np.argsort(counts))\n",
    "    # we need to convert the pixel from np.uint8 to int. Otherwise the transversion to the dataframe messes things up\n",
    "    most_frequent_true_color = unique_colors[most_frequent_indices[0]].astype(int)\n",
    "    rep_pixel_dict['true_R'].append(most_frequent_true_color[0])\n",
    "    rep_pixel_dict['true_G'].append(most_frequent_true_color[1])\n",
    "    rep_pixel_dict['true_B'].append(most_frequent_true_color[2])\n",
    "    \n",
    "    # inverted pixel\n",
    "    unique_colors, counts = np.unique(inv_pixels,axis=0,return_counts=True)\n",
    "    most_frequent_indices = np.flip(np.argsort(counts))\n",
    "    # we need to convert the pixel from np.uint8 to int. Otherwise the transversion to the dataframe messes things up\n",
    "    most_frequent_inverted_color = unique_colors[most_frequent_indices[0]].astype(int)\n",
    "    rep_pixel_dict['inv_R'].append(most_frequent_inverted_color[0])\n",
    "    rep_pixel_dict['inv_G'].append(most_frequent_inverted_color[1])\n",
    "    rep_pixel_dict['inv_B'].append(most_frequent_inverted_color[2])\n",
    "    \n",
    "# convert the dictionary to a dataframe\n",
    "pixel_df = pd.DataFrame(data=rep_pixel_dict, columns=rep_pixel_dict.keys())\n",
    "pixel_df.to_csv(os.path.join(stim_dir,'representative_pixels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0189cea7-efa8-4ba7-83b3-68db44982b21",
   "metadata": {},
   "source": [
    "#### an image of the colors for each hue value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e839c0b6-22e5-4369-ac64-a984c6135714",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = np.zeros((100,180,3),dtype='uint8')\n",
    "all_colors[:,:,0] = np.linspace(0,180,180)\n",
    "all_colors[:,:,1] = 100\n",
    "all_colors[:,:,2] = 150\n",
    "\n",
    "all_colors_rgb = cv2.cvtColor(all_colors, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(all_colors_rgb)\n",
    "plt.savefig(os.path.join(mask_dir,'hue_distribution.png'))\n",
    "plt.close(fig=fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
