{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10b476b-2545-49f6-a022-01e596a0cb38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stimulus playground\n",
    "This script is a playground to inspect and manipulate stimuli for a binocular rivalry (BR) experiment<br>\n",
    "In this experiment (as at April th) I aim to present objects that are associated with a color (e.g., banana - yellow, strawberry - red) in rivarous situations.<br>\n",
    "1. Show the same stimulus either in the \"correct\" and in an \"incorrect\" color (a banana in yellow and blue)\n",
    "2. Show two different stimuli that are associated with different colors but in the same color (a banana and a strawberry both in yellow)\n",
    "\n",
    "Compare the onset and sustained dominance with rivaling gratings that follow a series of non-rivaling gratings that appear to be rotating (Denison et al., 2011, Attarha et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc02fc-718e-4157-8d1f-061c8c9abb16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stimuli\n",
    "In the following I will look at the stimuli used by Bannert and Bartels 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f4fc70-b12f-4ea2-a00a-2a39b416d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# use the os\n",
    "import os\n",
    "import glob\n",
    "# math and data structure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# image processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f516e0b1-b5ae-4157-9ba1-62e94f1b999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "stim_dir = os.path.join('..', 'fuer_vincent', 'stimuli', 'equalizedStimuli')\n",
    "# get one example stimulus\n",
    "banana = os.path.join(stim_dir, 'banana', 'banana.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17581e11-225f-4d53-a5b5-cc8468dea3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimuli from Teichmann et al., 2020\n",
    "# provided by her OSF site (https://osf.io/tcqjh/)\n",
    "stim_dir = os.path.join('..','stimuli')\n",
    "original_stim_dir = os.path.join(stim_dir,'original')\n",
    "true_color_stim_dir = os.path.join(stim_dir,'true_color')\n",
    "inverted_color_stim_dir = os.path.join(stim_dir,'inverted')\n",
    "grey_stim_dir = os.path.join(stim_dir,'grey') # not used yet\n",
    "# get a list of all stimuli in the directory\n",
    "stimuli_full_path = glob.glob(os.path.join(original_stim_dir,'*.png'))\n",
    "stimuli_full_path.sort()\n",
    "\n",
    "# extract the image name from the stimulus path\n",
    "stimuli = [os.path.basename(stim) for stim in stimuli_full_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a7fca374-3905-4001-b243-3d1e710735cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read out the original stimuli and remove the background\n",
    "for stim_path, stim in zip(stimuli_full_path, stimuli):\n",
    "    # output directories\n",
    "    true_color_output_dir = os.path.join(true_color_stim_dir, stim)\n",
    "    inverted_color_output_dir = os.path.join(inverted_color_stim_dir, stim)\n",
    "    \n",
    "    # read in the original image\n",
    "    img = cv2.imread(stim_path)\n",
    "    \n",
    "    # convert image from BGR to HLS space\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    # create a copy of the hls_img and invert the hue\n",
    "    inverted_hls_img = np.copy(hls_img)\n",
    "    # select all pixels that are not white and increase the hue value by 90 (hue ranges from 0-179)\n",
    "    inverted_hls_img[np.where(hls_img[:,:,1]!=255)]+=np.array([90,0,0],dtype='uint8')\n",
    "    # convert inverted hls image back into BGR \n",
    "    inverted_bgr_img = cv2.cvtColor(inverted_hls_img, cv2.COLOR_HLS2BGR)\n",
    "    \n",
    "    # add alpha channel to original image by converting from BGR to BGRA space\n",
    "    bgra_img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "    # add alpha channel to inverted image by converting from BGR to BGRA space\n",
    "    inverted_bgra_img = cv2.cvtColor(inverted_bgr_img, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # change alpha channel of all pixels that are white to completely transparent\n",
    "    # CAUTION this results in pixels that are part of the stimulus to be transparent. \n",
    "    # Maybe I need to also create a mask based on the borders fot the stimulus\n",
    "    bgra_img[np.where(hls_img[:,:,1]==255)] -= np.array([0,0,0,255],dtype='uint8') \n",
    "    inverted_bgra_img[np.where(hls_img[:,:,1]==255)] -= np.array([0,0,0,255],dtype='uint8')\n",
    "    cv2.imwrite(true_color_output_dir,bgra_img)\n",
    "    cv2.imwrite(inverted_color_output_dir, inverted_bgra_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
